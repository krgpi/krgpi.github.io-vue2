<h1>Skills</h1>
<h3>Swift, JavaScript (Vue.js, Nuxt.js), Go</h3>
<h3>AWS, GCP, Firebase</h3>
<h3>Adobe Indesign, Photoshop, Lightroom</h3>
<hr />
<h1>Present</h1>
<h2>現在従事している業務もしくは学業</h2>
<h3>2020.3-</h3>
<h2>修士論文</h2>
<h3>Master Research</h3>
<p>機械学習を用いた参照動作の予期</p>
<br />
<h3>2019.10-</h3>
<h2><a href="https://letero.jp" target="_blank">Letero.jp</a></h2>
<h3>企画・開発およびチーム代表</h3>
<div class="container">
    <div class="item" width=100px>
        <img src="img/ideoj_logo_alpha.png" width="100px" />
    </div>
    <div class="item" style="max-width: 400px;">
        <p>インターネットで誰もが情報発信をできる時代になったが、一方的な発信が多く、議論のできる場所は少ないことに危機感を覚えるとともに、インターネットのポテンシャルを活かしたい意志のもと立ち上がる。建設的に議論ができる場所、発言者の立場が見える場所をインターネット上に作ることを目指す。</p>
    </div>
</div>
<br />
<h3>2019.6-</h3>
<h2>Pixiv</h2>
<p>pixivコミックのiOSアプリの開発に従事</p>

<br />
<h3>2018.3-</h3>
<h2><a href="http://ar-ap-inc.jp" target="_blank">Asahi AR</a></h2>
<div class="container">
    <div class="item" width=100px>
        <img src="img/AR_rogo.jpg" width="100px" />
    </div>

    <div class="item" style="max-width: 400px;">
        <p>AsahiARとは、紙媒体を始めとする現実世界のオブジェクトと、デジタルメディアを融合させる、"Augmented Reality (AR)"を使ったアプリケーションです。iOS, Webフロントエンド, バックエンドエンジニア, iOS UIデザイナー としてAsahi ARに関連するほとんどのプロダクトに携わっています。</p><br>
        <p>•Asahi AR combines paper media and digital contents such as movies and 3d objects. Users can not only read the book, but also see additional movies and 3d objects and more.

            Our object and a goal of this project is to compensate weakness of print media by digital media and to tell people about goodness of printing matter. With the widespread use of digital media, the number of print media is decreasing. However, there are strengths as the shapes of the book and the wonderful color expression. On the other hand, there are features that only be found in digital media such as videos, 3D interactive models.

        </p>
    </div>
</div>
<hr />


<h1>Past</h1>
<h2>過去に従事していた業務もしくは学業</h2>
<h3>2017.09-2019.08</h3>
<h2>産業技術総合研究所</h2>
<h3>National Institute of Advanced Industrial Science and Technology （AIST）</h3>
<p>２号契約職員(テクニカルスタッフ)として、岩石CT画像処理、3次元立体構造可視化などに従事した。</p>

<br />
<h3>2018.04-2019.03</h3>
<h2>卒業論文(学士)</h2>
<h3>Graduation Research on Bachelor</h3>
<p> Smart speaker, such as Google Assistant, Alexa or Siri is becoming ubiquitously available for the last few years. However, much research reported that users could not naturally interact with these commercial products since users need explicit utterances, which is also known as wake up words to activate them. Since a smooth conversation is obtained by several nonverbal behavior and verbal behaviour, I considered adding nonverbal behavior to smart speaker could achieve a smoother conversation. To achieve the purpose, I conducted an experiment to observe the participants ’natural movement while interacting with a smart speaker or a human. By video analysis, I extracted the significant nonverbal behaviour and considered them as important features in such conversation. Later, I implemented a prototype of smart speaker that support these features as activate function instead of wake up words. The result of evaluation shows that it is effective to use nonverbal behavior to activate a smart speaker.
</p>
